{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from os import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>modelName</th>\n",
       "      <th>WER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>openai/whisper-large-v3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>openai/whisper-large-v2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>facebook/seamless-m4t-v2-large</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>facebook/seamless-m4t-large</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>distil-whisper/distil-large-v2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>boris/xlsr-en-punctuation</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>espnet/Shinji_Watanabe_open_li52_asr_train_asr...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>facebook/s2t-medium-mustc-multilingual-st</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>facebook/s2t-small-covost2-en-fa-st</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>Jzuluaga/wav2vec2-xls-r-300m-en-atc-atcosim</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             modelName  WER\n",
       "0                              openai/whisper-large-v3  0.0\n",
       "1                              openai/whisper-large-v2  0.0\n",
       "2                       facebook/seamless-m4t-v2-large  0.0\n",
       "3                          facebook/seamless-m4t-large  0.0\n",
       "4                       distil-whisper/distil-large-v2  0.0\n",
       "..                                                 ...  ...\n",
       "115                          boris/xlsr-en-punctuation  0.0\n",
       "116  espnet/Shinji_Watanabe_open_li52_asr_train_asr...  0.0\n",
       "117          facebook/s2t-medium-mustc-multilingual-st  0.0\n",
       "118                facebook/s2t-small-covost2-en-fa-st  0.0\n",
       "119        Jzuluaga/wav2vec2-xls-r-300m-en-atc-atcosim  0.0\n",
       "\n",
       "[120 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "modelsList = [\n",
    "\t'openai/whisper-large-v3',\n",
    "\t'openai/whisper-large-v2',\n",
    "\t'facebook/seamless-m4t-v2-large',\n",
    "\t'facebook/seamless-m4t-large',\n",
    "\t'distil-whisper/distil-large-v2',\n",
    "\t'openai/whisper-large',\n",
    "\t'jonatasgrosman/wav2vec2-large-xlsr-53-english',\n",
    "\t'facebook/wav2vec2-base-960h',\n",
    "\t'nvidia/canary-1b',\n",
    "\t'openai/whisper-tiny',\n",
    "\t'guillaumekln/faster-whisper-large-v2',\n",
    "\t'Systran/faster-whisper-large-v3',\n",
    "\t'openai/whisper-medium',\n",
    "\t'openai/whisper-small',\n",
    "\t'openai/whisper-base',\n",
    "\t'distil-whisper/distil-large-v3',\n",
    "\t'facebook/wav2vec2-large-960h-lv60-self',\n",
    "\t'facebook/seamless-m4t-medium',\n",
    "\t'distil-whisper/distil-medium.en',\n",
    "\t'nvidia/parakeet-rnnt-1.1b',\n",
    "\t'facebook/mms-1b-all',\n",
    "\t'openai/whisper-tiny.en',\n",
    "\t'distil-whisper/distil-small.en',\n",
    "\t'nvidia/parakeet-tdt-1.1b',\n",
    "\t'facebook/hubert-large-ls960-ft',\n",
    "\t'nvidia/stt_en_conformer_transducer_xlarge',\n",
    "\t'openai/whisper-medium.en',\n",
    "\t'bababababooey/faster-whisper-large-v3',\n",
    "\t'guillaumekln/faster-whisper-medium',\n",
    "\t'tsinghua-ee/SALMONN',\n",
    "    \"voidful/wav2vec2-xlsr-multilingual-56\",\n",
    "    \"nvidia/stt_en_conformer_ctc_large\",\n",
    "    \"vitouphy/wav2vec2-xls-r-300m-timit-phoneme\",\n",
    "    \"openai/whisper-small.en\",\n",
    "    \"tsinghua-ee/SALMONN-7B\",\n",
    "    \"ivrit-ai/whisper-large-v2-tuned\",\n",
    "    \"facebook/s2t-small-librispeech-asr\",\n",
    "    \"openai/whisper-base.en\",\n",
    "    \"facebook/mms-1b-fl102\",\n",
    "    \"Systran/faster-whisper-large-v2\",\n",
    "    \"facebook/wav2vec2-large-960h\",\n",
    "    \"nvidia/stt_en_fastconformer_transducer_xlarge\",\n",
    "    \"speechbrain/m-ctc-t-large\",\n",
    "    \"nvidia/parakeet-ctc-1.1b\",\n",
    "    \"versae/whisper-large-v3\",\n",
    "    \"facebook/wav2vec2-large-robust-ft-swbd-300h\",\n",
    "    \"NbAiLab/nb-whisper-large\",\n",
    "    \"NbAiLab/nb-whisper-small-beta\",\n",
    "    \"facebook/wav2vec2-xls-r-2b-22-to-16\",\n",
    "    \"Systran/faster-distil-whisper-large-v3\",\n",
    "    \"facebook/hubert-xlarge-ls960-ft\",\n",
    "    \"nvidia/stt_en_fastconformer_transducer_xxlarge\",\n",
    "    \"distil-whisper/distil-large-v3-ggml\",\n",
    "    \"OthmaneJ/distil-wav2vec2\",\n",
    "    \"facebook/data2vec-audio-base-960h\",\n",
    "    \"facebook/wav2vec2-large-robust-ft-libri-960h\",\n",
    "    \"speechbrain/asr-crdnn-rnnlm-librispeech\",\n",
    "    \"speechbrain/asr-transformer-aishell\",\n",
    "    \"speechbrain/asr-wav2vec2-commonvoice-en\",\n",
    "    \"guillaumekln/faster-whisper-small\"\n",
    "    \"nvidia/parakeet-tdt_ctc-1.1b\",\n",
    "    \"jonatasgrosman/wav2vec2-xls-r-1b-english\",\n",
    "    \"bookbot/wav2vec2-ljspeech-gruut\",\n",
    "    \"guillaumekln/faster-whisper-base\",\n",
    "    \"rsonavane/distil-whisper-large-v2-8-ls\",\n",
    "    \"Systran/faster-whisper-medium\",\n",
    "    \"facebook/s2t-large-librispeech-asr\",\n",
    "    \"facebook/s2t-medium-librispeech-asr\",\n",
    "    \"facebook/wav2vec2-conformer-rope-large-960h-ft\",\n",
    "    \"speechbrain/asr-wav2vec2-librispeech\",\n",
    "    \"nvidia/stt_en_fastconformer_ctc_large\",\n",
    "    \"NbAiLab/nb-whisper-large-beta\",\n",
    "    \"NbAiLabBeta/nb-whisper-large\",\n",
    "    \"Systran/faster-distil-whisper-large-v2\",\n",
    "    \"facebook/wav2vec2-large-960h-lv60\",\n",
    "    \"speechbrain/asr-transformer-transformerlm-librispeech\",\n",
    "    \"speechbrain/asr-wav2vec2-transformer-aishell\",\n",
    "    \"facebook/data2vec-audio-large-960h\",\n",
    "    \"nvidia/stt_en_conformer_transducer_large\",\n",
    "    \"facebook/mms-1b-l1107\",\n",
    "    \"nvidia/stt_en_fastconformer_hybrid_large_streaming_multi\",\n",
    "    \"nvidia/parakeet-ctc-0.6b\",\n",
    "    \"ivrit-ai/whisper-v2-d3-e3\",\n",
    "    \"facebook/s2t-wav2vec2-large-en-ar\",\n",
    "    \"facebook/wav2vec2-xls-r-300m-en-to-15\",\n",
    "    \"patrickvonplaten/hubert-xlarge-ls960-ft-4-gram\",\n",
    "    \"mort666/faster-whisper-large-v2-th\",\n",
    "    \"speechbrain/asr-conformer-transformerlm-librispeech\",\n",
    "    \"Systran/faster-whisper-base\",\n",
    "    \"Systran/faster-whisper-small\",\n",
    "    \"spow12/Visual-novel-transcriptor\",\n",
    "    \"facebook/wav2vec2-base-100h\",\n",
    "    \"facebook/wav2vec2-xls-r-300m-21-to-en\",\n",
    "    \"yongjian/wav2vec2-large-a\",\n",
    "    \"Jzuluaga/wav2vec2-xls-r-300m-en-atc-uwb-atcc-and-atcosim\",\n",
    "    \"optimum/whisper-tiny.en\",\n",
    "    \"58AILab/wenet_efficient_conformer_aishell_v2\",\n",
    "    \"guillaumekln/faster-whisper-tiny\",\n",
    "    \"flyingleafe/faster-whisper-large-v3\",\n",
    "    \"nvidia/parakeet-rnnt-0.6b\",\n",
    "    \"mesolitica/malaysian-whisper-medium\",\n",
    "    \"distil-whisper/distil-large-v3-ct2\",\n",
    "    \"Crystalcareai/Whisper-Medicalv1\",\n",
    "    \"patrickvonplaten/wav2vec2-large-960h-lv60-self-4-gram\",\n",
    "    \"facebook/wav2vec2-conformer-rel-pos-large-960h-ft\",\n",
    "    \"nvidia/stt_be_conformer_transducer_large\",\n",
    "    \"vumichien/AV-HuBERT\",\n",
    "    \"58AILab/wenet_efficient_conformer_aishell_v1\",\n",
    "    \"danielus/ggml-whisper-models\",\n",
    "    \"nvidia/stt_en_fastconformer_transducer_large\",\n",
    "    \"hf-audio/wav2vec2-bert-CV16-en\",\n",
    "    \"NbAiLab/nb-whisper-medium\",\n",
    "    \"MahmoudAshraf/mms-300m-1130-forced-aligner\",\n",
    "    \"vonjack/whisper-large-v3-gguf\",\n",
    "    \"MohamedRashad/Arabic-Whisper-CodeSwitching-Edition\",\n",
    "    \"asapp/sew-d-base-plus-400k-ft-ls100h\",\n",
    "    \"boris/xlsr-en-punctuation\",\n",
    "    \"espnet/Shinji_Watanabe_open_li52_asr_train_asr_raw_bpe7000_valid.acc.ave\",\n",
    "    \"facebook/s2t-medium-mustc-multilingual-st\",\n",
    "    \"facebook/s2t-small-covost2-en-fa-st\",\n",
    "\t\"Jzuluaga/wav2vec2-xls-r-300m-en-atc-atcosim\"\n",
    "]\n",
    "\n",
    "data = {'modelName': modelsList, 'WER': [0.0] * len(modelsList)}\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "chdir(\"C:/Users/rowan/OneDrive/Desktop\\code/iResearch-2024/readme-files\")\n",
    "for i in range(len(modelsList)):\n",
    "\ttry:\n",
    "\t\tfile = requests.get('https://huggingface.co/' + modelsList[i] + '/raw/main/README.md').text\n",
    "\t\tif 'wer:' in file:\n",
    "\t\t\tprint(i)\n",
    "\t\t\tif ('wer:' in file):\n",
    "\t\t\t\ttry:\n",
    "\t\t\t\t\tvalue = file.split('wer:')[1].split(' ')[0]\n",
    "\t\t\t\t\twer = float(value)\n",
    "\t\t\t\texcept:\n",
    "\t\t\t\t\ttry:\n",
    "\t\t\t\t\t\tvalue.split(\"\\n\")[0]\n",
    "\t\t\t\t\texcept:\n",
    "\t\t\t\t\t\tprint(\"error\")\n",
    "\t\t\t\t\t\tcontinue\n",
    "\t\t\tprint(wer)\n",
    "\t\t\tdf.loc[i, 'WER'] = wer\n",
    "\n",
    "\texcept Exception as e:\n",
    "\t\tprint(e)\n",
    "\t\tcontinue\n",
    "\n",
    "df\n",
    "df.to_csv('WER.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
